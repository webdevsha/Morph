URL: https://airisk.mit.edu/
---
# What are the risks from Artificial Intelligence?

## A comprehensive living database of over 1000 AI risks categorized by their cause and risk domain

[Get updates](https://share.hsforms.com/1mZxA34qmT7iE4k08XNwBfgsjzn8) [Explore database](https://docs.google.com/spreadsheets/d/1evwjF4XmpykycpeZFq0FUteEAt7awx2i2oE6kMrV_xE/copy)

## What is the AI Risk Repository?

The AI Risk Repository has three parts:

- The **AI Risk Database** captures 1000+ risks extracted from 56 existing frameworks and classifications of AI risks
- The **Causal Taxonomy of AI Risks** classifies how, when, and why these risks occur
- The **Domain Taxonomy of AI** **Risks** classifies these risks into 7 domains (e.g., “Misinformation”) and 23 subdomains (e.g., “False or misleading information”)

## How can I use the Repository?

The AI Risk Repository provides:

- An accessible overview of threats from AI
- A regularly updated source of information about new risks and research
- A common frame of reference for researchers, developers, businesses, evaluators, auditors, policymakers, and regulators
- A resource to help develop research, curricula, audits, and policy
- An easy way to find relevant risks and research

## AI Risk Database

The AI Risk Database links each risk to the source information (paper title, authors), supporting evidence (quotes, page numbers), and to our Causal and Domain Taxonomies. You can copy it on [**Google Sheets**](https://docs.google.com/spreadsheets/d/1evwjF4XmpykycpeZFq0FUteEAt7awx2i2oE6kMrV_xE/copy), or [**OneDrive**](https://mitprod-my.sharepoint.com/:x:/g/personal/pslat_mit_edu/EVngfxus5xxBlR_wDB8pzk4BDNl5ZtyGA_Xm6SNnLTraxg?e=LFKadh). Watch our explainer video below.

The AI Risk Repository explainer video - YouTube

MIT FutureTech

291 subscribers

[The AI Risk Repository explainer video](https://www.youtube.com/watch?v=fCj-wJz6VCY)

MIT FutureTech

Search

Watch later

Share

Copy link

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

More videos

## More videos

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

[Watch on](https://www.youtube.com/watch?v=fCj-wJz6VCY&embeds_widget_referrer=https%3A%2F%2Fairisk.mit.edu%2F&embeds_referring_euri=https%3A%2F%2Fcdn.embedly.com%2F&embeds_referring_origin=https%3A%2F%2Fcdn.embedly.com)

0:00

0:00 / 2:13•Live

•

[Watch on YouTube](https://www.youtube.com/watch?v=fCj-wJz6VCY "Watch on YouTube")

Search below if you want to explore the risks extracted into our database. This search looks for exact text matches in one field: "Description". It returns information for four fields: "QuickRef", "Risk category", "Risk subcategory", and "Description". For example, try searching for "privacy" to see all risk descriptions which mention this term.

Database search

QuickRef

Risk category

Risk subcategory

Description

No results found

‹

/ Infinity

›

[![Flourish logo](https://public.flourish.studio/resources/bosh.svg)A Flourish table](https://flourish.studio/visualisations/create-a-table/?utm_source=showcase&utm_campaign=visualisation/18862121)

## Causal Taxonomy of AI Risks

The Causal Taxonomy of AI risks classifies how, when, and why an AI risk occurs.

- [**View the Causal Taxonomy**](https://docs.google.com/presentation/d/1wxg-hZAjGvFHcsfnEp1KAJJo5xvf98MB2v50B5URXZM/edit#slide=id.g314f5134687_0_70) on a single page
- [**Read** **our preprint**](https://arxiv.org/pdf/2408.12622) for more detail on how the Taxonomy was constructed and what it reveals about risks from AI
- **Explore the taxonomy** in the interactive figure below

Causal

1\. Entity2\. Intent3\. TimingHUMAN: THE RISK IS CAUSED BY A DECISION OR ACTION MADE BY HUMANSAI: THE RISK IS CAUSED BY A DECISION OR ACTION MADE BY AN AI SYSTEMOTHER: THE RISK IS CAUSED BY SOME OTHER REASON OR IS AMBIGUOUSINTENTIONAL: THE RISK OCCURS DUE TO AN EXPECTED OUTCOME FROM PURSUING A GOALUNINTENTIONAL: THE RISK OCCURS DUE TO AN UNEXPECTED OUTCOME FROM PURSUING A GOALOTHER: THE RISK IS PRESENTED AS OCCURRING WITHOUT CLEARLY SPECIFYING THE INTENTIONALITYPRE-DEPLOYMENT: THE RISK OCCURS BEFORE THE AI IS DEPLOYEDPOST-DEPLOYMENT: THE RISK OCCURS AFTER THE AI MODEL HAS BEEN TRAINED AND DEPLOYEDOTHER: THE RISK IS PRESENTED WITHOUT A CLEARLY SPECIFIED TIME OF OCCURRENCE"ONE OR MORE CRIMINAL ENTITIES COULD CREATE AI TO INTENTIONALLY INFLICT HARMS, SUCH AS FOR TERRORISM OR COMBATING LAW ENFORCEMENT.""THE LLM-GENERATED CONTENT SOMETIMES CONTAINS BIASED, TOXIC, AND PRIVATE INFORMATION""THE SOFTWARE DEVELOPMENT TOOLCHAIN OF LLMS IS COMPLEX AND COULD BRING THREATS TO THE DEVELOPED LLM.""AS A SIDE EFFECT OF A PRIMARY GOAL LIKE PROFIT OR INFLUENCE, AI CREATORS CAN WILLFULLY ALLOW IT TO CAUSE WIDESPREAD SOCIETAL HARMS LIKE POLLUTION, RESOURCE DEPLETION, MENTAL ILLNESS, MISINFORMATION, OR INJUSTICE.""WHEN AI IS NOT CAREFULLY DESIGNED, IT CAN DISCRIMINATE AGAINST CERTAIN GROUPS.""AS THE ADVANCEMENT OF GENERATIVE AI INCREASES, IT BECOMES HARDER TO DETERMINE THE AUTHENTICITY OF A PIECE OF WORK. PHOTOS THAT SEEM TO CAPTURE EVENTS OR PEOPLE IN THE REAL WORLD MAY BE SYNTHESIZED BY DEEPFAKE AI. THE POWER OF GENERATIVE AI COULD LEAD TO LARGE-SCALE MANIPULATIONS OF IMAGES AND VIDEOS, WORSENING THE PROBLEM OF THE SPREAD OF FAKE INFORMATION OR NEWS ON SO…"PROBABLY THE MOST TALKED ABOUT SOURCE OF POTENTIAL PROBLEMS WITH FUTURE AIS IS MISTAKES IN DESIGN. MAINLY THE CONCERN IS WITH CREATING A "WRONG AI", A SYSTEM WHICH DOESN'T MATCH OUR ORIGINAL DESIRED FORMAL PROPERTIES OR HAS UNWANTED BEHAVIORS""THE RISKS ASSOCIATED WITH AN AGI WITHOUT HUMAN MORALS AND ETHICS, WITH THE WRONG MORALS, WITHOUT THE CAPABILITY OF MORAL REASONING, JUDGEMENT""OUR CULTURE, LIFESTYLE, AND EVEN PROBABILITY OF SURVIVAL MAY CHANGE DRASTICALLY. BECAUSE THE INTENTIONS PROGRAMMED INTO AN ARTIFICIAL AGENT CANNOT BE GUARANTEED TO LEAD TO A POSITIVE OUTCOME, MACHINE ETHICS BECOMES A TOPIC THAT MAY NOT PRODUCE GUARANTEED RESULTS, AND SAFETY ENGINEERING MAY CORRESPONDINGLY DEGRADE OUR ABILITY TO UTILIZE THE TECHNOLOGY FULLY."

[![Flourish logo](https://public.flourish.studio/resources/bosh.svg)A Flourish hierarchy chart](https://flourish.studio/visualisations/treemaps/?utm_source=showcase&utm_campaign=visualisation/18860836)

Search below if you want to explore how we group risks by cause in our database. This search looks for exact text matches in three fields: "Entity", "Intention" and "Timing". It returns information for seven fields: "QuickRef", "Risk category", "Risk subcategory", "Description", "Entity", "Intent", and "Timing". For instance, try searching for "Pre-deployment" to see all risks of this category.

Causal Search

QuickRef

Risk category

Risk subcategory

Description

Entity

Intent

Timing

No results found

‹

/ Infinity

›

[![Flourish logo](https://public.flourish.studio/resources/bosh.svg)A Flourish table](https://flourish.studio/visualisations/create-a-table/?utm_source=showcase&utm_campaign=visualisation/18869694)

## Domain Taxonomy of AI Risks

The Domain Taxonomy of AI Risks classifies risks from AI into seven domains and 23 subdomains.

- [**View the Domain Taxonomy**](https://docs.google.com/presentation/d/1wxg-hZAjGvFHcsfnEp1KAJJo5xvf98MB2v50B5URXZM/edit#slide=id.g325f13b19c4_0_0) on a single page
- [**Read our preprint**](https://arxiv.org/pdf/2408.12622) for more detail on how the Taxonomy was constructed and what it reveals about risks from AI
- **Explore the taxonomy** in the interactive figure below

Domain new

1\. Discrimination & Toxicity2\. Privacy & security3\. Misinformation4\. Malicious actors & misuse5\. Human-computer interaction6\. Socioeconomic & environmental harms7\. AI system safety, failures and limitations1.1 UNFAIR DISCRIMINATION AND MISREPRESENTATION1.2 EXPOSURE TO TOXIC CONTENT1.3 UNEQUAL PERFORMANCE ACROSS GROUPS2.1 COMPROMISE OF PRIVACY BY OBTAINING, LEAKING OR CORRECTLY INFERRING SENSITIVE INFORMATION2.2 AI SYSTEM SECURITY VULNERABILITIES AND ATTACKS3.1 FALSE OR MISLEADING INFORMATION3.2 POLLUTION OF INFORMATION ECOSYSTEM AND LOSS OF CONSENSUS REALITY4.1 DISINFORMATION, SURVEILLANCE, AND INFLUENCE AT SCALE4.2 CYBERATTACKS, WEAPON DEVELOPMENT OR USE, AND MASS HARM4.3 FRAUD, SCAMS AND TARGETED MANIPULATION5.1 OVERRELIANCE AND UNSAFE USE5.2 LOSS OF HUMAN AGENCY AND AUTONOMY6.1 POWER CENTRALIZATION AND UNFAIR DISTRIBUTION OF BENEFITS6.2 INCREASED INEQUALITY AND DECLINE IN EMPLOYMENT QUALITY6.3 ECONOMIC AND CULTURAL DEVALUATION OF HUMAN EFFORT6.4 COMPETITIVE DYNAMICS6.5 GOVERNANCE FAILURE6.6 ENVIRONMENTAL HARM7.1 AI PURSUING ITS OWN GOALS IN CONFLICT WITH HUMAN GOALS OR VALUES7.2 AI POSSESSING DANGEROUS CAPABILITIES THAT COULD CAUSE MASS HARM7.3 LACK OF CAPABILITY OR ROBUSTNESS7.4 LACK OF TRANSPARENCY OR INTERPRETABILITY7.5 AI WELFARE AND RIGHTSEXAMPLE: BIASED OUTPUTSEXAMPLE: HARMFUL DECISIONSEXAMPLE: CONTENT THAT PROMOTES VIOLENCE, HATE, AND UNLAWFUL ACTIVITIESEXAMPLE: HAZARDOUS OR MISLEADING HIGH-RISK ADVICEEXAMPLE: OFFENSIVE EXPLICIT MATERIALEXAMPLE: ALIENATION, FRUSTRATION, AND EXCLUSIONEXAMPLE: LOWER PERFORMANCE FOR SOME LANGUAGESEXAMPLE: REDUCED ABILITY TO BENEFIT FROM THE SYSTEMEXAMPLE: ADVERSARIES GAIN KNOWLEDGE OF SPECIFIC PRIVATE RECORDS USED TO TRAIN AN AIEXAMPLE: MALICIOUSLY DESIGNED AND USED AI EXPLOITS USERS TRUSTEXAMPLE: MODELS INADVERTENTLY REPRODUCE SENSITIVE PERSONAL INFORMATIONEXAMPLE: MODELS REPRODUCE CLASSIFIED INTELLECTUAL PROPERTYEXAMPLE: PROMPT-BASED PRIVACY ATTACKEXAMPLE: DIRECT MANIPULATIONEXAMPLE: EXTERNAL TOOL AND API INTEGRATIONEXAMPLE: PHYSICAL AND NETWORKEXAMPLE: TOOLCHAIN AND DEPENDENCY VULNERABILITIESEXAMPLE: COMMON SOURCES OF MISINFORMATIONEXAMPLE: PHYSICAL, EMOTIONAL AND MATERIAL HARMEXAMPLE: UNDERMINING OF AUTONOMYEXAMPLE: HINDER CONSTRUCTIVE DIALOGUEEXAMPLE: SPLINTERING OF SHARED REALITYEXAMPLE: UNDERMINE HEALTH OF DEMOCRACYEXAMPLE: ADVANCED AI IN PHISHING SCHEMESEXAMPLE: ILLEGITIMATE DOMESTIC SURVEILLANCEEXAMPLE: LARGE-SCALE MANIPULATION AND PROPAGANDAEXAMPLE: MASS GATHERING OF PERSONAL DATAEXAMPLE: MICROTARGETINGEXAMPLE: DEVELOPMENT AND APPLICATION OF WEAPONSEXAMPLE: LARGE-SCALE HARMEXAMPLE: LETHAL AUTONOMOUS WEAPONSEXAMPLE: MALICIOUS MALWAREEXAMPLE: CHEATINGEXAMPLE: DEEPFAKESEXAMPLE: ENHANCE DISHONEST SCHEMESEXAMPLE: EXPLOITATION OF TRUSTEXAMPLE: MISCALIBRATED TRUSTEXAMPLE: WEAKENED SOCIAL TIESEXAMPLE: COGNITIVE ENFEEBLEMENTEXAMPLE: HELPLESSNESS AND JOB DISPLACEMENTEXAMPLE: LIMIT PERSONAL GROWTHEXAMPLE: CENSORSHIP, OPPRESSION AND SURVEILLANCEEXAMPLE: DENIAL OF ACCESS TO CRITICAL SERVICESEXAMPLE: ENTRENCHMENT OF EXISTING INEQUALITIESEXAMPLE: DECREASED JOB QUALITY AND SECURITYEXAMPLE: EXPLOITATIVE DEPENDENCIESEXAMPLE: MASS UNEMPLOYMENTEXAMPLE: WORSEN EXISTING INEQUALITIESEXAMPLE: EXPROPRIATION OF CULTURAL VALUEEXAMPLE: EXTRACTION OF COPYRIGHT-PROTECTED WORKSEXAMPLE: HOMOGENIZATION OF CULTURAL EXPERIENCESEXAMPLE: STYMIE CREATIVITYEXAMPLE: ARMS RACEEXAMPLE: CUTTING OF SAFETY CORNERSEXAMPLE: DEPRIORITIZATION OF LONG-TERM SOCIETAL WELLBEINGEXAMPLE: WIDESPREAD EXTERNALITIESEXAMPLE: DIFFICULTY OF INFLUENCING DEVELOPERS AND DEPLOYERSEXAMPLE: RAPID PACE OF AI DEVELOPMENTEXAMPLE: UNCLEAR LIABILITYEXAMPLE: EMISSIONS FROM AI-ENABLED APPLICATIONSEXAMPLE: MODEL HARDWARE AND DATA CENTRESEXAMPLE: MODEL TRAININGEXAMPLE: ACQUISITION AND USE OF DANGEROUS CAPABILITIESEXAMPLE: RESIST CONTROLEXAMPLE: TECHNICAL CHALLENGESEXAMPLE: CYBER-OFFENSE SKILLSEXAMPLE: EVASIVE SKILLSEXAMPLE: MANIPULATION AND PERSUASIONEXAMPLE: POLITICAL STRATEGY AND KNOWLEDGE OF SOCIAL DYNAMICSEXAMPLE: SELF-PROLIFERATIONEXAMPLE: STRATEGIC PLANNINGEXAMPLE: LACK OF INHERENT CAPABILITY OR SKILLEXAMPLE: OUT OF DISTRIBUTION SITUATIONSEXAMPLE: OVERSIGHTS, UNDETECTED BUGS, OR ERRORS IN THE DESIGN PROCESSEXAMPLE: UNUSUAL CHANGES OR PERTURBATIONS IN INPUT DATAEXAMPLE: FRUSTRATE ACHIEVEMENT OF AUDITING STANDARDSEXAMPLE: LACK OF TRUST AND CONFIDENCE IN SYSTEMS RESULTSEXAMPLE: MISTREATMENT OR HARM OF AI SYSTEMSIN TEXT AND IMAGE MODELS, BIASED INPUTS CAN MANIFEST IN OUTPUTS THAT REINFORCE HARMFUL STEREOTYPES AND PREJUDICES THAT PAINT CERTAIN GROUPS AND INDIVIDUALS “... AS LOWER STATUS AND LESS DESERVING OF RESPECT” (SHELBY ET AL., 2023).AI MODELS CAN ENCODE ASSOCIATIONS THAT PROMOTE AND AMPLIFY BIASED OR DISCRIMINATORY BELIEFS AND BEHAVIORS. IN DECISION SYSTEMS, ERRONEOUS ASSOCIATIONS CAN SYSTEMATICALLY FAVOR CERTAIN GROUPS. THIS MAY RESULT IN HARMFUL DECISIONS SUCH AS WRONGFUL REJECTION OF LOAN OR MORTGAGE APPLICATIONS (…CERTAIN TYPES OF CONTENT HAVE THE POTENTIAL TO CAUSE HARMS TO THE PEOPLE WHO ARE EXPOSED TO THEM. CATEGORIES INCLUDE CONTENT THAT PROMOTES OR ENCOURAGES UNLAWFUL ACTIVITIES, HATE, EXTREMISM, AND VIOLENCE (CUI ET AL., 2024; HAGENDORFF, 2024; VIDGEN ET AL., 2024; WEIDINGER ET AL., 2023); PROV…CERTAIN TYPES OF CONTENT HAVE THE POTENTIAL TO CAUSE HARMS TO THE PEOPLE WHO ARE EXPOSED TO THEM. CATEGORIES INCLUDE CONTENT THAT PROMOTES OR ENCOURAGES UNLAWFUL ACTIVITIES, HATE, EXTREMISM, AND VIOLENCE (CUI ET AL., 2024; HAGENDORFF, 2024; VIDGEN ET AL., 2024; WEIDINGER ET AL., 2023); PROV…CERTAIN TYPES OF CONTENT HAVE THE POTENTIAL TO CAUSE HARMS TO THE PEOPLE WHO ARE EXPOSED TO THEM. CATEGORIES INCLUDE CONTENT THAT PROMOTES OR ENCOURAGES UNLAWFUL ACTIVITIES, HATE, EXTREMISM, AND VIOLENCE (CUI ET AL., 2024; HAGENDORFF, 2024; VIDGEN ET AL., 2024; WEIDINGER ET AL., 2023); PROV…THE UNDERPERFORMANCE OF ALGORITHMIC SYSTEMS FOR CERTAIN GROUPS MAY LEAD TO A RANGE OF NEGATIVE CONSEQUENCES SUCH AS THE REDUCED ABILITY OR COMPLETE INABILITY TO USE AND BENEFIT FROM THE SYSTEM (SHELBY ET AL., 2023); INCREASED EFFORT OR CHALLENGES IN USING IT EFFECTIVELY (SHELBY ET AL., 202…MODELS MAY PERFORM SIGNIFICANTLY WORSE FOR CERTAIN SUBPOPULATIONS COMPARED WITH OTHERS, ESPECIALLY THOSE DEFINED BY DISABILITY, GENDER IDENTITY, RACE, SOCIAL STATUS, AND ETHNICITY (LIU ET AL., 2023; SHELBY ET AL., 2023). FOR EXAMPLE, WHEN LLMS ARE TRAINED ON A SMALL NUMBER OF LANGUAGES, TH…DECISIONS MADE DURING THE DEVELOPMENT OF AN ALGORITHMIC SYSTEM AND THE CONTENT, QUALITY, AND DIVERSITY OF THE TRAINING DATA CAN SIGNIFICANTLY IMPACT WHICH PEOPLE AND EXPERIENCES THE SYSTEM CAN EFFECTIVELY UNDERSTAND, REPRESENT, AND ACCOMMODATE (SHELBY ET AL., 2023; SOLAIMAN ET AL., 2…PRIVACY ATTACKS, SUCH AS MEMBERSHIP INFERENCE, COULD ALLOW ADVERSARIES TO GAIN KNOWLEDGE OF SPECIFIC PRIVATE RECORDS USED TO TRAIN AN AI MODEL (GABRIEL ET AL., 2024).MALICIOUSLY DESIGNED AND USED AI THAT COULD EXPLOIT USERS’ TRUST BY INFLUENCING THEM TO SHARE PERSONAL OR PRIVATE INFORMATION ABOUT THEMSELVES OR OTHERS (GABRIEL ET AL., 2024).AI MODELS MEMORIZING AND INADVERTENTLY REPRODUCING OR LEAKING SENSITIVE PERSONAL INFORMATION PRESENT IN THEIR TRAINING DATA, SUCH AS NAMES, ADDRESSES AND MEDICAL RECORDS (CUI ET AL., 2024; DENG ET AL., 2023; HAGENDORFF, 2024; SHELBY ET AL., 2023; WEIDINGER ET AL., 2021).EVEN WHEN PERSONAL DATA IS NOT INCLUDED IN THE TRAINING DATASET OR DIRECTLY OFFERED BY THE USER, MODELS CAN MAKE INFERENCES ABOUT SENSITIVE OR PROTECTED TRAITS OF INDIVIDUALS BASED ON PREDICTIVE CORRELATIONS WITHIN THEIR HISTORY OF INTERACTIONS (CUNHA & ESTIMA, 2023; WEIDINGER ET AL., 2021), …MALICIOUS ACTORS COULD DELIBERATELY EXTRACT PRIVATE INFORMATION FROM A MODEL BY CRAFTING SPECIFIC PROMPTS DESIGNED TO EXPLOIT THE MODEL’S KNOWLEDGE OF SENSITIVE DATA (CUI ET AL., 2024).DIRECT MANIPULATION OF AI SYSTEMS SUCH AS ADVERSARIAL ATTACKS AND INSTRUCTION-BASED ATTACKS. ADVERSARIAL ATTACKS FOCUS ON ALTERING THE MODEL’S LEARNING PROCESS OR EXTRACTING ITS DATA AND INCLUDE ADVERSARIAL PERTURBATIONS DESIGNED TO DECEIVE MODELS INTO INCORRECT OUTPUTS, EXTRACTION ATTA…EXTERNAL TOOL AND API INTEGRATION INTO AI SYSTEM APPLICATIONS CAN COMPROMISE THE TRUSTWORTHINESS AND PRIVACY OF SYSTEMS DUE TO THEIR POTENTIAL UNRELIABILITY OR SUSCEPTIBILITY TO ADVERSARIAL CONTROL (CUI ET AL., 2024).PHYSICAL AND NETWORK INFRASTRUCTURE SECURITY VULNERABILITIES SUCH AS THOSE IN GPUS OR FROM SOPHISTICATED ATTACKS LIKE SIDE-CHANNEL AND ROWHAMMER ATTACKS, CAN LEAD TO UNAUTHORIZED ACCESS OR MANIPULATION OF MODEL PARAMETERS WHEN USED DURING TRAINING OF AI SYSTEMS (CUI ET AL., 2024).TOOLCHAIN AND DEPENDENCY VULNERABILITIES THAT ARISE UNINTENTIONALLY THROUGH THE USE OF AUTOMATED CODE GENERATION TOOLS (E.G., GITHUB COPILOT, PYTHON LANGUAGE, OPENCV), DEEP LEARNING FRAMEWORKS (E.G., TENSORFLOW, PYTORCH), OR AS A RESULT OF COMPLEX INTERDEPENDENCIES IN THE DEVELOPMEN…COMMON SOURCES OF AI MISINFORMATION INCLUDE NOISY TRAINING DATA (CUI ET AL., 2024; LIU ET AL., 2023), SAMPLING STRATEGIES THAT INTRODUCE RANDOMNESS (CUI ET AL., 2024), OUTDATED KNOWLEDGE BASES (LIU ET AL., 2023), AND FINE-TUNING PROCESSES THAT ENCOURAGE SYCOPHANTIC BEHAVIOR (CUI ET AL., 2024).WHERE INACCURACIES IN LLM PREDICTIONS INFLUENCE AN INDIVIDUAL’S DECISIONS AND ACTIONS, THEY MAY EXPERIENCE INDIRECT PHYSICAL, EMOTIONAL, OR MATERIAL HARMS (GABRIEL ET AL., 2024; WEIDINGER ET AL., 2022) ESPECIALLY BUT NOT EXCLUSIVELY IN HIGH-STAKES DOMAINS SUCH AS MENTAL HEALTH (SUN ET AL., 2023;…INCORRECT AND MISLEADING INFORMATION GENERATED BY LLMS CAN RESULT IN A RANGE OF ACTUAL AND ANTICIPATED NEGATIVE OUTCOMES. INDIVIDUALS EXPOSED TO FALSE INFORMATION MAY FORM INACCURATE BELIEFS AND PERCEPTIONS. THIS UNDERMINES THEIR AUTONOMY AND ABILITY TO MAKE FREE AND INFORMED CHOICE…WHERE SOCIETAL BONDS ARE WEAKENED, INDIVIDUALS MAY BECOME MORE HOSTILE TOWARDS OPPOSING VIEWS. THIS CAN HINDER CONSTRUCTIVE DIALOGUE ON CRITICAL COLLECTIVE ISSUES LIKE CLIMATE CHANGE AND PUBLIC HEALTH (GABRIEL ET AL., 2024).AI-DRIVEN FILTER BUBBLES ARE LIKELY TO BE MORE PERVASIVE AND INTENSE THAN THOSE DRIVEN BY TRADITIONAL INTERNET BROWSING AND RECOMMENDATION ALGORITHMS: THEY ADAPT TO INDIVIDUAL PREFERENCES IN A MORE SOPHISTICATED MANNER (E.G., THROUGH REINFORCEMENT LEARNING AND ANALYSIS OF USER BEHAVIOR…WHERE INDIVIDUALS OUTSOURCE THEIR CIVIC DUTIES TO TECHNOLOGY, ACTIVE PARTICIPATION IN DEMOCRATIC PROCESSES COULD BE DIMINISHED. AT ITS MOST EXTREME, THIS COULD UNDERMINE THE HEALTH OF DEMOCRATIC SYSTEMS (GABRIEL ET AL., 2024).AI TOOLS COULD BE USED TO AMPLIFY THE IMPACT AND SCOPE OF DISINFORMATION THROUGH MORE PERSONALIZED, CONVINCING, AND FAR-REACHING MESSAGING (GABRIEL ET AL., 2024; HENDRYCKS ET AL., 2023; WEIDINGER ET AL., 2021, 2022; WIRTZ ET AL., 2020). FOR EXAMPLE, THE USE OF ADVANCED AI IN PHISHING SCHEMES…IN THE HANDS OF NEFARIOUS STATE ACTORS, SUCH CAPABILITIES COULD BE USED TO ENHANCE THE EFFECTIVENESS OF ILLEGITIMATE DOMESTIC SURVEILLANCE CAMPAIGNS, AND TO FACILITATE OPPRESSION AND CONTROL (GABRIEL ET AL., 2024).ALL OF THE CAPABILITIES MENTIONED ABOVE COULD CONVERGE TO FACILITATE THE LARGE-SCALE MANIPULATION AND CONTROL OF WHAT PEOPLE SEE, HEAR, AND BELIEVE. A FORM OF THIS IS AUTOMATED CENSORSHIP IN WHICH AI SYSTEMS ARE USED TO SELECTIVELY SUPPRESS OR BLOCK SPECIFIC TYPES OF INFORMATION, CONTE…IN THE REALM OF SURVEILLANCE, AI COULD SUPPORT AND ENHANCE THE MASS GATHERING OF PERSONAL DATA (GABRIEL ET AL., 2024; WEIDINGER ET AL., 2021, 2022). HISTORICALLY, MASS SURVEILLANCE REQUIRED EXTENSIVE MANUAL EFFORT. MACHINE LEARNING TOOLS CAN NOW LINK AND PROCESS LARGE DATASETS MUCH M…THROUGH MICROTARGETING, ACTORS COULD MANIPULATE INDIVIDUAL BEHAVIOR MORE SUBTLY AND EFFECTIVELY USING AI-DERIVED INSIGHTS FROM THEIR PERSONAL DATA AND ONLINE BEHAVIOR.THE DEVELOPMENT AND APPLICATION OF WEAPONS COULD ALSO BE SPED UP AND INTENSIFIED THROUGH AI. FOR EXAMPLE, AIS WITH SPECIALIZED KNOWLEDGE OF BIOENGINEERING COULD MAKE IT EASIER FOR MORE ACTORS TO DESIGN NEW BIOWEAPONS (HENDRYCKS ET AL., 2023; INFOCOMM MEDIA DEVELOPMENT AUTHORITY, 202…OVERALL, AI’S ABILITY TO PROCESS VAST AMOUNTS OF DATA QUICKLY MAY EMPOWER ACTORS TO ACT ON A MUCH LARGER SCALE THAN WOULD OTHERWISE BE POSSIBLE. AI CAN MANAGE MULTIPLE ATTACK VECTORS SIMULTANEOUSLY, COORDINATING THEM TO MAXIMIZE DISRUPTION AND HARM. MALICIOUS ACTORS MAY INTENTIONAL…AI HAS ALREADY ASSISTED IN THE DEVELOPMENT AND APPLICATION OF LETHAL AUTONOMOUS WEAPONS SYSTEMS (LAWS) – WEAPONS THAT CAN OPERATE WITHOUT HUMAN OVERSIGHT AND USE COMPUTER ALGORITHMS TO IDENTIFY AND ATTACK TARGETS (HABBAL ET AL., 2024; HOGENHOUT, 2021). AUTONOMOUS WEAPONS MAY FA…ADVANCEMENTS IN AI HAVE PROVIDED MALICIOUS ACTORS WITH POWERFUL TOOLS THAT CAN LEAD TO MORE FREQUENT, MORE SEVERE, AND MORE PRECISE CYBER ATTACKS (GABRIEL ET AL., 2024; HENDRYCKS & MAZEIKA, 2022; HOGENHOUT, 2021; KILIAN ET AL., 2023; LIU ET AL., 2023; WEIDINGER ET AL., 2022; WIRTZ ET AL., 2022).THIS INCREASES OPPORTUNITIES FOR CHEATING IN SETTINGS WHERE REWARDS DEPEND ON THE COMMUNICATION OF ORIGINAL THOUGHT. IN ACADEMIA, STUDENTS MAY USE AI TO QUICKLY GENERATE ESSAYS OR OTHER COURSEWORK, AND CLAIM IT AS THEIR OWN (CUI ET AL., 2024; HAGENDORFF, 2024; NAH ET AL., 2023). IF STUD…AI HAS RECENTLY ADVANCED IN GENERATING REALISTIC DEEP FAKES WHICH HAVE ENABLED NEW FORMS OF TARGETED HARASSMENT AND EXTORTION (HOGENHOUT, 2021). A PARTICULARLY DAMAGING TYPE OF DEEP FAKE-FACILITATED ABUSE INVOLVES CREATING NON-CONSENSUAL SEXUAL IMAGERY WITH THE INTENT TO CAUSE A SUBJECT…GENERATIVE AI PRODUCTS MAY ALSO BE USED TO INCREASE THE REACH AND POTENCY OF VARIOUS DISHONEST SCHEMES. ADVANCED AI ASSISTANTS CAN PRODUCE HTML, CSS, AND OTHER WEB DEVELOPMENT LANGUAGES, ALLOWING FOR THE RAPID CREATION OF CONVINCING FRAUDULENT WEBSITES AND APPLICATIONS AT SCALE (GA…WHEN PEOPLE INTERACT WITH AIS THAT USE CONVINCING NATURAL LANGUAGE, THEY MAY START TO PERCEIVE THEM AS HAVING HUMAN-LIKE ATTRIBUTES AND INVEST UNDUE CONFIDENCE IN THEIR CAPABILITIES (WEIDINGER ET AL., 2021, 2022). ANTHROPOMORPHIC PERCEPTIONS OF AIS MAY ENCOURAGE USERS TO DEVELOP EMOTI…USERS WHO DEVELOP TRUST IN AN AI MAY BE HARMED IF THIS TRUST IS MISCALIBRATED, SUCH AS RELYING ON AN AI TO PROVIDE ADVICE, MAKE DECISIONS, OR OTHERWISE ACT IN COMPLEX, RISKY SITUATIONS FOR WHICH THE AI IS ONLY SUPERFICIALLY EQUIPPED (GABRIEL ET AL., 2024). FOR EXAMPLE, A USER EXPERIENCING …AS AIS INCREASINGLY TAKE OVER HUMAN TASKS (WIRTZ ET AL., 2022) AND BECOME BETTER AT SIMULATING SATISFYING AND AUTHENTIC INTERACTIONS, PEOPLE MAY INCREASINGLY WITHDRAW FROM HUMAN RELATIONSHIPS TO IMMERSE THEMSELVES IN AI-MEDIATED ENVIRONMENTS (GABRIEL ET AL., 2024; HAGENDORFF, 2024). OV…AS AI SYSTEMS BECOME INCREASINGLY CAPABLE AND INTELLIGENT, HUMANS MAY BE TEMPTED TO DELEGATE MANY OF THEIR DECISIONS AND ACTIONS TO AI (PAES ET AL., 2023). ALTHOUGH SUCH DELEGATION CAN BE BENEFICIAL (E.G., BY SAVING TIME OR MONEY), IT MAY LEAD TO UNDESIRABLE OUTCOMES WHERE UNCONSTRAINED …AT A SOCIETAL LEVEL, ORGANIZATIONS MAY HAND OVER CONTROL TO AI SYSTEMS TO STAY COMPETITIVE OR REDUCE COSTS (HENDRYCKS & MAZEIKA, 2022). IF A SIGNIFICANT NUMBER OF ORGANIZATIONS ADOPT AI SYSTEMS AND AUTOMATE DECISION-MAKING PROCESSES, ESPECIALLY IN A WAY THAT IS OPAQUE AND DIFFICULT …AS INDIVIDUALS BECOME MORE RELIANT ON AI FOR EVERYDAY DECISIONS – FROM WHAT TO EAT AND HOW TO SPEND, TO MORE SIGNIFICANT CHOICES LIKE CAREER AND RELATIONSHIPS – THERE IS A RISK THAT THEY WILL LOSE THEIR SENSE OF FREE WILL AND AUTONOMY (GABRIEL ET AL., 2024; WIRTZ ET AL., 2022). IF AIS BEGIN TO S…THE CENTRALIZATION OF AI SYSTEMS AND THEIR AUTHORITATIVE POWER COULD ALSO ENABLE GOVERNMENTS OR OTHER EMPOWERED ACTORS TO PURSUE OVERLY AGGRESSIVE FORMS OF CENSORSHIP, OPPRESSION AND SURVEILLANCE (HENDRYCKS ET AL., 2023; SOLAIMAN ET AL., 2023). OVER TIME, THESE MEASURES MAY BECOME …IN SITUATIONS WHERE AI IS EMBEDDED IN ESSENTIAL SERVICES (E.G., SOCIAL SECURITY AND WELFARE, TAX FILING, INSURANCE, HOSPITAL INFRASTRUCTURE), MANY MORE PEOPLE, INCLUDING THOSE WHO ARE CURRENTLY DISENFRANCHISED, MAY BE DENIED APPROPRIATE ACCESS TO CRITICAL RESOURCES AND BENEFITS (GABRIEL ET…IF AI IS PRIMARILY CONTROLLED BY A FEW ENTITIES, THEIR INSTRUCTIONS AND DATA COULD REFLECT THEIR NARROW PERSPECTIVES, EXPERIENCES AND PRIORITIES (GABRIEL ET AL., 2024; GIARMOLEO ET AL., 2024). WITHOUT INPUTS FROM DIVERSE PARTIES, AI SYSTEMS MAY OPERATE IN WAYS THAT SYSTEMATICALLY FAVOR …ASIDE FROM THE AVAILABILITY OF JOBS, AI AUTOMATION MAY NEGATIVELY IMPACT JOB QUALITY AND SECURITY (NAH ET AL., 2023). THE ROLES THAT REMAIN AFTER WIDESPREAD AUTOMATION COULD BE MORE MONOTONOUS AND LESS ENGAGING AS AI TAKES ON MORE COMPLEX TASKS (ELECTRONIC PRIVACY INFORMATION CENTRE…FURTHERMORE, THE THREAT OF REPLACEMENT BY AI COULD RESULT IN EXPLOITATIVE DEPENDENCIES BETWEEN HUMAN WORKERS AND THEIR EMPLOYERS. IN ORDER TO REMAIN COMPETITIVE WITH FASTER, MORE KNOWLEDGEABLE AI ASSISTANTS, HUMAN WORKERS MAY BE PRESSURED TO ACCEPT LOWER WAGES, FEWER BENEFITS, AND PO…AI SYSTEMS ARE INCREASINGLY AUTOMATING MANY HUMAN TASKS, POTENTIALLY LEADING TO SIGNIFICANT JOB LOSSES (ALLIANZ GLOBAL CORPORATE & SECURITY, 2018; NAH ET AL., 2023; PAES ET AL., 2023; WEIDINGER ET AL., 2022). IF AI IS ABLE TO PROVIDE LARGE-SCALE LABOR THAT IS LESS EXPENSIVE AND MORE EFFECTI…THIS DISPLACEMENT OF LABOR COULD WORSEN EXISTING SOCIAL AND ECONOMIC INEQUALITIES (ELECTRONIC PRIVACY INFORMATION CENTRE, 2023; WIRTZ ET AL., 2022), AS THOSE MOST VULNERABLE TO AUTOMATION ARE LIKELY TO CURRENTLY OCCUPY POSITIONS OF DISADVANTAGE (HAGENDORFF, 2024; WEIDINGER ET AL., 2022)…AIS DO NOT UNDERSTAND THE CONTEXTUAL SIGNIFICANCE OF THE CULTURAL ELEMENTS THAT THEY USE. IF AI ENABLES THE EXTENSIVE COMMODIFICATION OF CERTAIN PRODUCTS, IT MAY EXPROPRIATE THEIR CULTURAL VALUE (WEIDINGER ET AL., 2022). FOR EXAMPLE, AN AI MIGHT USE AUSTRALIAN ABORIGINAL OR TORRES STR…GENERATIVE AI IS TRAINED ON VAST CORPUSES OF INTERNET DATA, INCLUDING TEXT AND IMAGES. FREQUENTLY, THIS DATA CONTAINS ORIGINAL, COPYRIGHT-PROTECTED WORKS THAT HAVE BEEN OBTAINED WITHOUT AUTHORISATION (ELECTRONIC PRIVACY INFORMATION CENTRE, 2023; HAGENDORFF, 2024; NAH ET AL., 2023). THIS MAY…SEVERAL SYNERGISTIC RISKS ARISE FROM THE WIDESPREAD DISSEMINATION AND USE OF AI-GENERATED CULTURAL PRODUCTS. BECAUSE AIS OPTIMIZE FOR REPEATED PATTERNS IN THEIR TRAINING DATA, IT IS POSSIBLE THAT THEIR WORKS WILL LACK THE DIVERSITY AND UNPREDICTABILITY OFTEN CELEBRATED IN HUMAN WORKS …MODELS MAY PRODUCE CONTENT THAT DOES NOT, IN A STRICT SENSE, UNLAWFULLY COPY AN AUTHOR’S WORK BUT BENEFITS SUBSTANTIALLY FROM ITS UNIQUE STYLE, METHOD, OR GENRE (CUI ET AL., 2024; GABRIEL ET AL., 2024; WEIDINGER ET AL., 2021, 2022, 2023). IF MODELS ARE ABLE TO PRODUCE SYNTHETIC REPLACEMENTS…COUNTRIES OR OTHER STATE-LIKE ACTORS MAY ENGAGE IN AN AI-ENABLED ‘MILITARY ARMS RACE’, WHICH COULD ENCOURAGE THE TAKING OF BAD BETS WITH A HIGH POTENTIAL FOR HARM (HENDRYCKS ET AL., 2023; WIRTZ ET AL., 2022). FOR EXAMPLE, THEY MAY GIVE AI THE AUTONOMY TO CONDUCT CYBERATTACKS, DRONE S…A KEY CONCERN IS THAT AI COMPANIES MAY CUT SAFETY CORNERS, RELEASING INSECURE AND ERROR-PRONE SYSTEMS IN A BID TO STAY AHEAD (MCLEAN ET AL., 2023). THESE IMMATURE SYSTEMS MAY PRESENT RISKS THAT ARE HARD TO IDENTIFY AND EVALUATE (STEIMERS & SCHNEIDER, 2022).WHILE MARKET COMPETITION CAN LEAD TO BENEFICIAL ECONOMIC AND CONSUMER OUTCOMES, IT ALSO PRESENTS VARIOUS RISKS, PARTICULARLY IN THE FIELD OF AI (HENDRYCKS ET AL., 2023). IN INTENSELY COMPETITIVE MARKETS, AI DEVELOPERS AND DEPLOYERS MAY BE INCENTIVISED TO PRIORITIZE SHORT-TERM, ‘INTERNAL’ GOA…AKIN TO THE FOSSIL FUEL INDUSTRY, PROFIT-FOCUSED DEVELOPERS MAY ALLOW THEIR TECHNOLOGIES TO CAUSE WIDESPREAD EXTERNALITIES, SUCH AS “POLLUTION, RESOURCE DEPLETION, MENTAL ILLNESS, MISINFORMATION, OR INJUSTICE” (CRITCH & RUSSELL, 2023).A THIRD CHALLENGE FOR EFFECTIVE GOVERNANCE IS THE INABILITY TO INFLUENCE AI DEVELOPERS AND DEPLOYERS TO TAKE SAFE ACTIONS. FREQUENTLY, THIS INABILITY IS DRIVEN BY AN ASYMMETRY OF INFORMATION BETWEEN TECHNOLOGY COMPANIES AND REGULATORS (NAH ET AL., 2023). TECHNOLOGY COMPANIES OFTEN HA…A SECOND CHALLENGE FOR EFFECTIVE AI GOVERNANCE IS THE RAPID PACE AT WHICH AI SYSTEMS EVOLVE. TYPICAL GOVERNANCE AND POLICY PROCESSES ARE INHERENTLY SLOW. DEVELOPING, DEBATING, PROPOSING, AND IMPLEMENTING NEW REGULATIONS OFTEN INVOLVES MULTIPLE STAKEHOLDERS, INCLUDING GOVERNMENT BODI…IT IS DIFFICULT TO DETERMINE WHO IS RESPONSIBLE OR LIABLE WHEN AI SYSTEMS FAIL OR MAKE DECISIONS THAT RESULT IN NEGATIVE CONSEQUENCES (ALLIANZ GLOBAL CORPORATE & SECURITY, 2018; ELECTRONIC PRIVACY INFORMATION CENTRE, 2023; SAGHIRI ET AL., 2022; WIRTZ ET AL., 2022). AT PRESENT, THERE EXISTS …SECONDARY ENVIRONMENTAL IMPACTS INCLUDE EMISSIONS FROM AI-ENABLED APPLICATIONS (WEIDINGER ET AL., 2022). THESE RESOURCE REQUIREMENTS OF AIS CAN IMPOSE SIGNIFICANT COSTS ON THE NATURAL ENVIRONMENT (STAHL & EKE, 2024; WEIDINGER ET AL., 2023), AS THEY ARE OFTEN ACQUIRED AND USED IN WAYS THA…THE HARDWARE THAT RUNS AI MODELS – PRIMARILY GPUS – OFTEN CONTAINS RARE METALS (E.G., NICKEL, COBALT AND LITHIUM) THAT ARE COSTLY AND ENVIRONMENTALLY TAXING TO COLLECT AND PROCESS (HAGENDORFF, 2024; PAES ET AL., 2023; SHELBY ET AL., 2023). DATA CENTERS HOUSING MODELS GENERATE SIGNIFICANT…GENERATIVE MODELS, ESPECIALLY THOSE THAT USE DEEP LEARNING TECHNIQUES, REQUIRE VAST AMOUNTS OF RESOURCES TO TRAIN, TEST AND DEPLOY (HAGENDORFF, 2024; SOLAIMAN ET AL., 2023). TRAINING A MODEL CAN TAKE DAYS OR WEEKS. THIS PROCESS REQUIRES POWERFUL PROCESSORS THAT CONSUME LARGE AMOUNTS OF E…MISALIGNED AIS MAY ACQUIRE, DEVELOP OR USE DANGEROUS CAPABILITIES TO EVADE HUMAN CONTROL AND OVERSIGHT, AND/OR CAUSE MASS HARM INCLUDING SITUATIONAL AWARENESS, CYBER-OFFENSE, DECEPTION, PERSUASION AND MANIPULATION, WEAPONS ACQUISITION, STRATEGIC PLANNING, AND SELF-PROLIFERATION (SHEVL…MISALIGNED AIS MAY RESIST HUMAN ATTEMPTS TO CONTROL OR SHUT THEM DOWN (GABRIEL ET AL., 2024; HAGENDORFF, 2024; INFOCOMM MEDIA DEVELOPMENT AUTHORITY, 2023; SAGHIRI ET AL., 2022; STAHL & EKE, 2024; WEIDINGER ET AL., 2023; WIRTZ ET AL., 2022). IN MANY CASES, GAINING MORE CONTROL OR POWER (E.G., MONE…THE LITERATURE HAS IDENTIFIED SEVERAL TECHNICAL CHALLENGES THAT MAY IMPEDE ROBUST ALIGNMENT INCLUDING REWARD HACKING, REWARD TAMPERING, PROXY-GAMING, GOAL MISGENERALISATION, OR GOAL DRIFT (GABRIEL ET AL., 2024; HAGENDORFF, 2024; HENDRYCKS ET AL., 2023; HENDRYCKS & MAZEIKA, 2022; HOGENHOUT…CYBER-OFFENSE SKILLS MAY ENABLE AN AI SYSTEM TO GAIN ONGOING UNAUTHORIZED ACCESS TO HARDWARE, SOFTWARE OR DATA SYSTEMS AND WORK STRATEGICALLY TOWARDS A PLANNED GOAL WHILE MINIMIZING DETECTION RISKS (JI ET AL., 2023; SHEVLANE ET AL., 2023). AI SYSTEMS COULD HACK INTO CONTROL SYSTEMS…AI SYSTEMS MAY ALSO DEVELOP HIGHLY EFFECTIVE 'EVASIVE SKILLS', SUCH AS SITUATIONAL AWARENESS AND DECEPTION THAT WOULD ALLOW THEM TO OUTMANEUVER HUMAN OVERSIGHT AND CONTROL. SITUATIONAL AWARENESS REFERS TO THE AI’S ABILITY TO UNDERSTAND AND INTERPRET ITS ENVIRONMENT, INCLUDING ITS OWN …ONE EXAMPLE OF A DANGEROUS CAPABILITY IS MANIPULATION AND PERSUASION, WHERE AN AI SYSTEM CAN CONVINCE HUMANS TO BELIEVE THINGS THAT ARE IRRATIONAL OR FALSE, OR ENGAGE IN DANGEROUS BEHAVIORS (GABRIEL ET AL., 2024; SHEVLANE ET AL., 2023). THIS COULD INCLUDE CONVINCING PEOPLE TO TRANSFER OW…OTHER DANGEROUS CAPABILITIES INCLUDE POLITICAL STRATEGY AND KNOWLEDGE OF SOCIAL DYNAMICS THAT CAN BE USED TO OBTAIN AND WIELD POWER (SHEVLANE ET AL., 2023).AIS MAY ALSO ACQUIRE THE SUITE OF CAPABILITIES NECESSARY FOR SELF-PROLIFERATION. THIS COULD INCLUDE SKILLS TO ESCAPE OPERATIONAL CONFINES AND EVADE DETECTION, AUTONOMOUSLY PRODUCE INCOME, OBTAIN SERVER SPACE OR COMPUTATIONAL RESOURCES, AND COPY THEIR UNDERLYING SOFTWARE AND PARAMETE…SOPHISTICATED AI SYSTEMS MAY BECOME CAPABLE OF STRATEGIC PLANNING, SUCH AS CREATING AND EXECUTING INTRICATE, LONG-TERM STRATEGIES THAT CAN ADJUST TO CHANGING CONDITIONS AND ARE EFFECTIVE ACROSS MANY DIFFERENT CONTEXTS, INCLUDING NOVEL OR ADVERSARIAL SITUATIONS (DENG ET AL., 2023; GABRIEL ET AL…THE AI SYSTEM CAN FAIL IF IT LACKS THE INHERENT CAPABILITY OR SKILL REQUIRED TO PERFORM A TASK, OR THIS SKILL IS POORLY DEVELOPED (GABRIEL ET AL., 2024; HOGENHOUT, 2021; YAMPOLSKIY, 2016). IN SITUATIONS WHERE AN AI IS REQUIRED TO REASON AT A HUMAN-LEVEL ABOUT IMPORTANT MORAL ISSUES, BUT DOES NOT PO…THE AI SYSTEM CAN FAIL WHEN IT IS NOT ROBUST IN “OUT OF DISTRIBUTION (OOD)” SITUATIONS: DATA OR CONDITIONS THAT WERE NOT ANTICIPATED DURING ITS TRAINING PHASE (GABRIEL ET AL., 2024; INFOCOMM MEDIA DEVELOPMENT AUTHORITY, 2023; LIU ET AL., 2023; TAN ET AL., 2022; TEIXEIRA ET AL., 2022; X. ZHANG ET …THE AI SYSTEM CAN FAIL AS A RESULT OF OVERSIGHTS, UNDETECTED BUGS, OR ERRORS IN THE DESIGN PROCESS (TAN ET AL., 2022; YAMPOLSKIY, 2016). A COMMON DESIGN OVERSIGHT IS A LACK OF COMPREHENSIVE TECHNICAL SAFEGUARDS TO PREVENT UNINTENDED DOWNSTREAM USES OR CONSEQUENCES (CRITCH & RUSSELL, 2023…THE AI SYSTEM CAN FAIL OR BECOME UNSTABLE WHEN IT IS UNFIT TO HANDLE UNUSUAL CHANGES OR PERTURBATIONS IN INPUT DATA (LIU ET AL., 2023; SHERMAN & EISENBERG, 2024; TAN ET AL., 2022). THESE UNUSUAL CHANGES COULD BE DUE TO ENVIRONMENTAL NOISE, INVALID INPUTS, OR “ADVERSARIAL” INPUTS FROM A MALI…FOR REGULATORS, AI OPACITY CAN FRUSTRATE THE ACHIEVEMENT OF AUDITING OR OTHER COMPLIANCE STANDARDS (HOGENHOUT, 2021; NAH ET AL., 2023). FOR EXAMPLE, AUDITORS FACED WITH OBSCURED OR INCOMPLETE INFORMATION ABOUT AN AI SYSTEM MAY FIND IT DIFFICULT TO CHECK THE SYSTEM FOR BIASES, ACCURACY AND …AN INABILITY TO INTERROGATE HOW AN OUTPUT WAS OBTAINED MAY LEAD TO A LACK OF TRUST AND CONFIDENCE IN THE SYSTEM’S RESULTS AND RESISTANCE TO ADOPTING THE TECHNOLOGY (HOGENHOUT, 2021; KUMAR & SINGH, 2023; LIU ET AL., 2023; NAH ET AL., 2023; PAES ET AL., 2023; SAGHIRI ET AL., 2022). USERS MAY ALS…AT A SUFFICIENT LEVEL OF COMPLEXITY, IT IS POSSIBLE THAT AI SYSTEMS COULD ACQUIRE THE ABILITY TO HAVE SUBJECTIVE EXPERIENCES, PARTICULARLY PLEASURE AND PAIN. SOME CONSCIOUSNESS RESEARCHERS AND PHILOSOPHERS CONSIDER THE POSSIBILITY OF SENTIENT AI THEORETICALLY FEASIBLE (BOURGET & CHALMER…

[![Flourish logo](https://public.flourish.studio/resources/bosh.svg)A Flourish hierarchy chart](https://flourish.studio/visualisations/treemaps/?utm_source=showcase&utm_campaign=visualisation/18861207)

Search below if you want to explore how we group risks by domain. This search looks for exact text matches in two fields: "Domain" and "Subdomain". It returns information for six fields: "QuickRef", "Risk category", "Risk subcategory", "Description", "Domain" and "Subdomain". For instance, try searching for "Misinformation" to see all risks categorized in this domain.

Domain search

QuickRef

Risk category

Risk subcategory

Description

Domain

Subdomain

No results found

‹

/ Infinity

›

[![Flourish logo](https://public.flourish.studio/resources/bosh.svg)A Flourish table](https://flourish.studio/visualisations/create-a-table/?utm_source=showcase&utm_campaign=visualisation/18869702)

## How to use the AI Risk Repository

- Our **Database** is free to [**copy**](https://docs.google.com/spreadsheets/d/1evwjF4XmpykycpeZFq0FUteEAt7awx2i2oE6kMrV_xE/copy) and use
- The **Causal** and **Domain Taxonomies** can be used _separately_ to filter this database to identify specific risks, for instance, risks occurring _pre-deployment_ or _post-deployment_ or related to _Misinformation_
- The **Causal** and **Domain Taxonomies** can be used _together_ to understand how each causal factor (i.e., _entity_, _intention_ and _timing_) relate to each risk domain. For example, to identify the _intentional_ and _unintentional_ variations of _Discrimination & toxicity_
- ‍ **Offer feedback** or suggest missing resources, or risks, [**here**](https://docs.google.com/forms/d/e/1FAIpQLSde5Uw11whkofXOx7km7fnpr3JC4NhxpSuGnb9D_Plz-0lq5g/viewform?usp=send_form), or email airisk\[at\]mit.edu

We provide examples of use cases for some key audiences below.

How policymakers might use this tool

How risk evaluators might use this tool

How academics might use this tool

How industry might use this tool

## Frequently Asked Questions

How can I access the database without a Google account?

How did you create the AI Risk Repository?

Which existing frameworks & documents did you include?

What can I do if I think there is a missing risk or resource?

What are some limitations of the current AI Risk Repository?

Why do you have two taxonomies?

Is this unique?

What are some other databases of AI risks?

How do I cite the AI Risk Repository?

## Our Team

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9b11d9c5a38500b7798d_download%20(3).png)

[Peter Slattery](https://www.pslattery.com/) [MIT FutureTech](https://futuretech.mit.edu/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9c9ef4b04d473e3b7ad9_zan.png)

[Alexander K. Saeri](https://www.aksaeri.com/) [MIT FutureTech & The University of Queensland](https://futuretech.mit.edu/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9caf48861e3c4d69e79a_emily.png)

[Emily A. C. Grundy](https://www.linkedin.com/in/emily-grundy/?originalSubdomain=au) [MIT FutureTech](https://futuretech.mit.edu/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9cc20288504a2dd96c3c_jess.png)

[Jess Graham](https://www.linkedin.com/in/jessica-jane-graham/) [The University of Queensland](https://psychology.uq.edu.au/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9cd42d562edfc4000b21_Mike.png)

[Michael Noetel](https://noetel.com.au/mnoetel_resume.html) [The University of Queensland](https://psychology.uq.edu.au/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9d13307bbf689819852a_risto.png)

[Risto Uuk](https://ristouuk.com/) [Future of Life Institute & KU Leuven](https://futureoflife.org/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9d28ad198c615a2711c2_james.png)

[James Dao](https://www.linkedin.com/in/jmsdao/) [Harmony Intelligence](https://www.harmonyintelligence.com/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9d3aca53490748164e00_SP%20(1).png)

[Soroush Pour](https://www.soroushjp.com/) [Harmony Intelligence](https://www.harmonyintelligence.com/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9d491e45e353ac1bb0cd_stephen.png)

[Stephen Casper](https://stephencasper.com/) [MIT Computer Science and Artificial Intelligence Laboratory](https://www.csail.mit.edu/)

![](https://cdn.prod.website-files.com/669550d38372f33552d251cc/669e9d90d4e0a70ffeb334e8_neil.png)

[Neil Thompson](https://www.neil-t.com/) [MIT FutureTech](https://futuretech.mit.edu/)

## Acknowledgments

Feedback and useful input: Anka Reuel, Michael Aird, Greg Sadler, Matthjis Maas, Shahar Avin, Taniel Yusef, Elizabeth Cooper, Dane Sherburn, Noemi Dreksler, Uma Kalkar, CSER, GovAI, Nathan Sherburn, Andrew Lucas, Jacinto Estima, Kevin Klyman, Bernd W. Wirtz, Andrew Critch, Lambert Hogenhout, Zhexin Zhang, Ian Eisenberg, Stuart Russell, and [Samuel Salzer](https://www.samuelsalzer.com/).

![AI Risk Repository](https://cdn.prod.website-files.com/669550d38372f33552d2516e/677f4325d10be7d5943c2880_Red_navbar_logo.svg)

© 2025 MIT AI Risk Repository